{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Instagram_Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TC72E9183EA8",
        "6Q0qgo263I8-",
        "0XCm3A-R5dz9",
        "dCXJIdO0XOTb",
        "1L7BuVJvzGph",
        "98la3SPSrc8E"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radonys/webscrapers/blob/master/Instagram_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yj9mSL8crNZ_",
        "colab_type": "text"
      },
      "source": [
        "# Instagram Scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC72E9183EA8",
        "colab_type": "text"
      },
      "source": [
        "## Install Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrj6WjtD29wx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install bs4 selenium pandas scikit-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q0qgo263I8-",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfYzdXBh3OoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For accessing and parsing Instagram Webpages\n",
        "from selenium import webdriver\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.request import urlopen\n",
        "import json\n",
        "\n",
        "# Structuring Collected Data\n",
        "import pandas as pd\n",
        "\n",
        "# General Libraries\n",
        "import time\n",
        "import re\n",
        "import os\n",
        "import requests"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XCm3A-R5dz9",
        "colab_type": "text"
      },
      "source": [
        "## Install Chrome Driver for scrolling Instagram pages\n",
        "\n",
        "References:\n",
        "\n",
        "1) How can we use Selenium Webdriver in colab.research.google.com? [[StackOverFlow](https://stackoverflow.com/questions/51046454/how-can-we-use-selenium-webdriver-in-colab-research-google-com)]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyTQqoqO5lLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt install chromium-chromedriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JedNtqhE6pPd",
        "colab_type": "text"
      },
      "source": [
        "## Variable Declarations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fOUojXr6vFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "browser = webdriver.Chrome('chromedriver',options=options)\n",
        "\n",
        "#Instagram Handles to be scraped\n",
        "instagram_handles = ['walmart']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdMCzsRGzRNf",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions for Scraping, Parsing & Save"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6hdVXkJ_Xhi",
        "colab_type": "text"
      },
      "source": [
        "### Instagram Scraper Function\n",
        "\n",
        "References:\n",
        "\n",
        "1) Scraping Instagram with Python (using Selenium and Beautiful Soup) ([Medium](https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058))\n",
        "\n",
        "2) How to scroll to the end of the page using selenium in python ([StackOverFlow](https://stackoverflow.com/questions/32391303/how-to-scroll-to-the-end-of-the-page-using-selenium-in-python/32629481))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tTJ4p7x_cHU",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#The Code has been referenced from the above two resources which have been combined together as per the needs of the desired program. \n",
        "\n",
        "def instagram_link_scraper(suffix, tagged=False):\n",
        "  \n",
        "  if tagged:\n",
        "    link = 'https://www.instagram.com/'+suffix+'/tagged/'\n",
        "  else:\n",
        "    link = 'https://www.instagram.com/'+suffix\n",
        "  \n",
        "  browser.get(link)\n",
        "  \n",
        "  page_length = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var page_length=document.body.scrollHeight;return page_length;\")\n",
        "  flag = False\n",
        "  links = []\n",
        "  \n",
        "  while flag==False:\n",
        "    \n",
        "    previous_length = page_length\n",
        "    \n",
        "    #Sleep Time added so fake that Instagram page is not being traversed by a Bot.\n",
        "    time.sleep(3)\n",
        "    print(len(set(links)))\n",
        "    \n",
        "    page_length = browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);var page_length=document.body.scrollHeight;return page_length;\")\n",
        "    \n",
        "    #If the previous length is equal to current length, that means we are at the end of the page.\n",
        "    if previous_length==page_length:\n",
        "      flag = True\n",
        "    \n",
        "    #Collect image/video links on the current page.\n",
        "    \n",
        "    if tagged==False:\n",
        "    \n",
        "      source = browser.page_source\n",
        "      data = BeautifulSoup(source, 'html.parser')\n",
        "    \n",
        "      #Post links in the HTML code are in the Body tag.\n",
        "      body = data.find('body')\n",
        "      script = body.find('span')\n",
        "      \n",
        "      for link in script.findAll('a'):\n",
        "         if re.match(\"/p/\", link.get('href')):\n",
        "            links.append('https://www.instagram.com' + link.get('href'))\n",
        "    \n",
        "    else:\n",
        "      \n",
        "      #Page Refresh time.\n",
        "      time.sleep(5)\n",
        "      \n",
        "      data = browser.find_elements_by_tag_name(\"article\")\n",
        "      a_tags = data[0].find_elements_by_tag_name(\"a\")\n",
        "      \n",
        "      for link in a_tags:\n",
        "        links.append(link.get_attribute('href'))\n",
        "  \n",
        "  return list(set(links))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCXJIdO0XOTb",
        "colab_type": "text"
      },
      "source": [
        "### Retreive Needed Information from JSON Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_TBOs1UXTh9",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def extract_needed_info(json_data):\n",
        "  \n",
        "  keys = ['id', 'shortcode', 'edge_media_preview_like', 'display_url', 'is_video', 'edge_media_preview_comment', 'taken_at_timestamp']\n",
        "  temp_dict = {}\n",
        "  \n",
        "  for key in keys:\n",
        "    \n",
        "    if key not in json_data:\n",
        "      \n",
        "      if key=='edge_media_preview_comment':\n",
        "        temp_key = 'edge_media_to_parent_comment'\n",
        "        \n",
        "        if temp_key not in json_data:\n",
        "          temp_key = 'edge_media_to_comment'\n",
        "        \n",
        "      temp_dict[key] = json_data[temp_key]\n",
        "    \n",
        "    else:\n",
        "      temp_dict[key] = json_data[key]\n",
        "  \n",
        "  return temp_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1L7BuVJvzGph",
        "colab_type": "text"
      },
      "source": [
        "### Parse and Save Link Data\n",
        "\n",
        "References:\n",
        "\n",
        "1) Scraping Instagram with Python (using Selenium and Beautiful Soup) ([Medium](https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058))\n",
        "\n",
        "2) Manually raising (throwing) an exception in Python [StackOverFlow](https://stackoverflow.com/questions/2052390/manually-raising-throwing-an-exception-in-python)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvc3SEH5zYNB",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def save_metadata(links, save_name):\n",
        "  \n",
        "  data = pd.DataFrame()\n",
        "  counter = 0\n",
        "  total_links = len(links)\n",
        "  \n",
        "  while counter!=total_links:\n",
        "  \n",
        "    for link in links:\n",
        "    \n",
        "          try:\n",
        "          \n",
        "            # Open the URL and extract JSON information.\n",
        "            page = urlopen(link).read()\n",
        "            source = BeautifulSoup(page, 'html.parser')\n",
        "            body = source.find('body')\n",
        "            script = body.find('script')\n",
        "            json_extract = re.sub('window._sharedData =|;', '', script.text)\n",
        "            json_data = json.loads(json_extract)\n",
        "\n",
        "            # Extract needed information.\n",
        "            image_metadata = json_data['entry_data']['PostPage'][0]['graphql']['shortcode_media']\n",
        "            temp_dict = extract_needed_info(image_metadata)\n",
        "            temp = pd.DataFrame.from_dict(temp_dict, orient='columns')\n",
        "            data = data.append(temp)\n",
        "            links.remove(link)\n",
        "            counter = counter + 1\n",
        "            \n",
        "          except Exception as error:\n",
        "            print(link)\n",
        "            print('Caught this error: ' + repr(error))\n",
        "  \n",
        "  data = data.drop_duplicates(subset = 'shortcode')\n",
        "  data.index = range(len(data.index))\n",
        "  data.to_csv(save_name+'data.csv')\n",
        "  save_images(data, save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXL_UVor6ZFK",
        "colab_type": "text"
      },
      "source": [
        "### Save Images\n",
        "\n",
        "References:\n",
        "\n",
        "1) Scraping Instagram with Python (using Selenium and Beautiful Soup) ([Medium](https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQqGRL-U6epZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#The Code has been taken from the above resource.\n",
        "\n",
        "def save_images(data, save_name):\n",
        "  \n",
        "  images_path = save_name+'/'\n",
        "  \n",
        "  if not os.path.isdir(images_path):\n",
        "    os.mkdir(images_path)\n",
        "  \n",
        "  for i in range(0, len(data['display_url'])):\n",
        "    \n",
        "    image = requests.get(data['display_url'][i])\n",
        "    with open(images_path + data['shortcode'][i] + \".jpg\", 'wb') as file:\n",
        "                    file.write(image.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5SeH4gA9CjK",
        "colab_type": "text"
      },
      "source": [
        "## Scrape and Parsing Instagram Data\n",
        "\n",
        "Note: Data scraping for posts and tagged images of a handle has been seperated due to processing time constraints."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROk9ZXPp9HH1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for handle in instagram_handles:\n",
        "  \n",
        "  #links = instagram_link_scraper(handle)\n",
        "  #save_metadata(links,handle+'_posts_')\n",
        "  \n",
        "  links = instagram_link_scraper(handle, tagged=True)\n",
        "  print(len(links))\n",
        "  save_metadata(links,handle+'_tagged_')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCLzdeKxUI49",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXedY8C_UZfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r lazboy_tagged_images.zip lazboy_tagged_/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ7HgiuEUjD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv *.zip /content/drive/My\\ Drive/\n",
        "!mv *.csv /content/drive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98la3SPSrc8E",
        "colab_type": "text"
      },
      "source": [
        "## General References\n",
        "\n",
        "1) Pandas Docs ([Pandas](https://pandas.pydata.org/pandas-docs/stable/))\n",
        "\n",
        "2) Selenium WebDriver ([Selenium](https://www.seleniumhq.org/projects/webdriver/))"
      ]
    }
  ]
}