{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Scraper.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qKZlrLqbYuLP",
        "nQfS5-IqYxK_",
        "l2fmqU50cG-u",
        "BkLA5tXjck_b",
        "L74nv5p6GPR-",
        "cZPb97u0h30T",
        "H6HU_hKHSde0",
        "g6R9MwR0cLPH"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radonys/webscrapers/blob/master/Twitter_Scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dhI3KxGYqS6",
        "colab_type": "text"
      },
      "source": [
        "# Twitter Scraper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKZlrLqbYuLP",
        "colab_type": "text"
      },
      "source": [
        "## Install Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAhOpeBEYllq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tweepy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQfS5-IqYxK_",
        "colab_type": "text"
      },
      "source": [
        "## Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTDn2Cj0Yzv2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import os\n",
        "import requests\n",
        "import shutil\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cA0FpekZaEJ0",
        "colab_type": "text"
      },
      "source": [
        "## Variable Declarations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5pWno2XaxBK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_handles = ['AmSigFurniture', 'AshleyHomeStore', 'Bonobos', 'CocaCola', 'IKEAUSA', 'lazboy', 'potterybarn', 'raymourflanigan', 'SimplyGum', 'Star_Furniture', 'WilliamsSonoma']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1znspNUSbegc",
        "colab_type": "text"
      },
      "source": [
        "## Twitter Credentials"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2cFpuwtaIVu",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "\n",
        "1) How to Scrape Data from Twitter Using Python ([PromptCloud](https://www.promptcloud.com/blog/scrape-twitter-data-using-python-r/))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZqlHEnXcF4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Please upload the JSON file with Twitter Application Credentials')\n",
        "#files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZWcrD9IbhSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twitter_cred = dict()\n",
        "\n",
        "twitter_cred['CONSUMER_KEY'] = ''\n",
        "twitter_cred['CONSUMER_SECRET'] = ''\n",
        "twitter_cred['ACCESS_KEY'] = ''\n",
        "twitter_cred['ACCESS_SECRET'] = ''\n",
        "\n",
        "'''with open('twitter_credentials.json', 'r') as protected:\n",
        "  json.dump(twitter_cred, protected, sort_keys=True)'''\n",
        "\n",
        "authentication = OAuthHandler(twitter_cred['CONSUMER_KEY'], twitter_cred['CONSUMER_SECRET'])\n",
        "authentication.set_access_token(twitter_cred['ACCESS_KEY'], twitter_cred['ACCESS_SECRET'])\n",
        "\n",
        "twitter_api = tweepy.API(authentication)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2fmqU50cG-u",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkLA5tXjck_b",
        "colab_type": "text"
      },
      "source": [
        "### Retrieve Twitter Media Data & URL\n",
        "\n",
        "References:\n",
        "\n",
        "1) How to Scrape Data from Twitter Using Python ([PromptCloud](https://www.promptcloud.com/blog/scrape-twitter-data-using-python-r/))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgJaAZGFcKXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scrape_twitter_media(handle):\n",
        "  \n",
        "  global twitter_api\n",
        "  \n",
        "  tweets = twitter_api.user_timeline(screen_name=handle, count=200)\n",
        "  \n",
        "  last_tweet_id = tweets[len(tweets)-1].id\n",
        "  \n",
        "  flag = True\n",
        "  \n",
        "  while flag:\n",
        "    \n",
        "    next_tweets = twitter_api.user_timeline(screen_name=handle, count=200, max_id=last_tweet_id - 1)\n",
        "    \n",
        "    if len(next_tweets)==0:\n",
        "      flag = False\n",
        "    \n",
        "    else:\n",
        "      \n",
        "      tweets = tweets + next_tweets\n",
        "      last_tweet_id = tweets[len(tweets)-1].id\n",
        "    \n",
        "  return tweets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L74nv5p6GPR-",
        "colab_type": "text"
      },
      "source": [
        "### Select Relevant Information\n",
        "\n",
        "References:\n",
        "\n",
        "1) How to Scrape Data from Twitter Using Python ([PromptCloud](https://www.promptcloud.com/blog/scrape-twitter-data-using-python-r/))\n",
        "\n",
        "2) Convert Tweepy Status object into JSON ([StackOverFlow](https://stackoverflow.com/questions/27900451/convert-tweepy-status-object-into-json))\n",
        "\n",
        "3) Convert string to JSON using Python ([StackOverFlow](https://stackoverflow.com/questions/4528099/convert-string-to-json-using-python))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nJLQOX5GVsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def select_relevant_information(tweet):\n",
        "  \n",
        "  temp = dict()\n",
        "  key_values = ['id', 'created_at', 'id_str', 'retweet_count', 'favorite_count', 'user']\n",
        "  \n",
        "  media = tweet.entities.get('media', [])\n",
        "  \n",
        "  if len(media)>0:\n",
        "    \n",
        "    temp['media_url'] = [media[0]['media_url']]\n",
        "    json_data = json.loads(json.dumps(tweet._json))\n",
        "    \n",
        "    for key in key_values:\n",
        "      \n",
        "      if key=='user':\n",
        "        temp[key] = [json_data[key]['screen_name']]\n",
        "        \n",
        "      else:\n",
        "        temp[key] = [json_data[key]]\n",
        "        \n",
        "    return temp\n",
        "    \n",
        "  else:\n",
        "    \n",
        "    return None\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZPb97u0h30T",
        "colab_type": "text"
      },
      "source": [
        "### Save Metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzdZ0FxWh5mE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_metadata(tweets, save_name):\n",
        "  \n",
        "  data = pd.DataFrame()\n",
        "  \n",
        "  for tweet in tweets:\n",
        "    \n",
        "    temp_dict = select_relevant_information(tweet)\n",
        "    \n",
        "    if temp_dict!=None:\n",
        "      \n",
        "      tweet_data = pd.DataFrame.from_dict(temp_dict, orient='columns')\n",
        "      data = data.append(tweet_data)\n",
        "      \n",
        "  data.index = range(len(data.index))\n",
        "  data.to_csv(handle+'_data.csv')\n",
        "  save_images(data, handle+'_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6HU_hKHSde0",
        "colab_type": "text"
      },
      "source": [
        "### Save Images\n",
        "\n",
        "References:\n",
        "\n",
        "1) Scraping Instagram with Python (using Selenium and Beautiful Soup) ([Medium](https://medium.com/@srujana.rao2/scraping-instagram-with-python-using-selenium-and-beautiful-soup-8b72c186a058))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3o9MEg9SeZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_images(data, save_name):\n",
        "  \n",
        "  images_path = save_name+'/'\n",
        "  \n",
        "  if not os.path.isdir(images_path):\n",
        "    os.mkdir(images_path)\n",
        "  \n",
        "  for i in range(0, len(data['media_url'])):\n",
        "    \n",
        "    image = requests.get(data['media_url'][i])\n",
        "    \n",
        "    with open(images_path + data['id_str'][i] + \".jpg\", 'wb') as file:\n",
        "      file.write(image.content)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6R9MwR0cLPH",
        "colab_type": "text"
      },
      "source": [
        "## Scrape Twitter Media"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXjrtEyscNp6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for handle in twitter_handles:\n",
        "  \n",
        "  tweets = scrape_twitter_media(handle)\n",
        "  print(len(tweets))\n",
        "  save_metadata(tweets, handle)\n",
        "  shutil.make_archive(handle+'_images', 'zip', handle+'_images')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}